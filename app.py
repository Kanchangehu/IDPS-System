import streamlit as st
import pandas as pd
import numpy as np
import joblib
import gdown
import os

st.set_page_config(page_title="IDPS System", page_icon="üõ°Ô∏è", layout="wide")

MODEL_FILE_ID = "1ROjXla7J_wAEpaWBVPFR88pOxlZRAmbe"
SCALER_FILE_ID = "1tHV0P3yPbblm_8Lds9bRMyTnSdDLvu7n"
FEATURES_FILE_ID = "1fbREKxsJ4n3m_n1n6ExrQzpmeaXG9DIx"

@st.cache_resource
def load_all_files_safe():
    """Load model, scaler, and feature names"""
    model = None
    scaler = None
    feature_names = None
    
    try:
        if not os.path.exists('idps_model.joblib'):
            gdown.download(f'https://drive.google.com/uc?id={MODEL_FILE_ID}', 'idps_model.joblib', quiet=False)
        model = joblib.load('idps_model.joblib')
        st.success(f"‚úÖ Model loaded: {type(model).__name__}")
    except Exception as e:
        st.error(f"‚ùå Model error: {e}")
        return None, None, None
    
    try:
        if not os.path.exists('feature_scaler.joblib'):
            gdown.download(f'https://drive.google.com/uc?id={SCALER_FILE_ID}', 'feature_scaler.joblib', quiet=False)
        scaler = joblib.load('feature_scaler.joblib')
        st.success(f"‚úÖ Scaler loaded: {type(scaler).__name__}")
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Scaler not available, will use raw values")
        scaler = None
    
    try:
        if not os.path.exists('feature_names.joblib'):
            gdown.download(f'https://drive.google.com/uc?id={FEATURES_FILE_ID}', 'feature_names.joblib', quiet=False)
        feature_names = joblib.load('feature_names.joblib')
        st.success(f"‚úÖ Features loaded: {len(feature_names)} features")
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Features not available")
    
    return model, scaler, feature_names

# ============================================================================
# CSS STYLING
# ============================================================================
st.markdown("""
    <style>
        .header-container {
            background: linear-gradient(135deg, #0066cc 0%, #004499 100%);
            padding: 40px 20px;
            border-radius: 15px;
            text-align: center;
            margin-bottom: 30px;
            color: white;
        }
        .header-title {
            font-size: 2.8em;
            font-weight: bold;
            margin: 0;
        }
        .result-normal {
            background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
            padding: 25px;
            border-radius: 12px;
            text-align: center;
            color: white;
            font-size: 1.5em;
            font-weight: bold;
        }
        .result-attack {
            background: linear-gradient(135deg, #dc3545 0%, #ff6b6b 100%);
            padding: 25px;
            border-radius: 12px;
            text-align: center;
            color: white;
            font-size: 1.5em;
            font-weight: bold;
        }
    </style>
""", unsafe_allow_html=True)

st.markdown('<div class="header-container"><p class="header-title">üõ°Ô∏è IDPS - AI Intrusion Detection System</p></div>', unsafe_allow_html=True)

# Load files
model, scaler, feature_names = load_all_files_safe()

if model is None:
    st.error("‚ùå Cannot load model. Check FILE_IDs!")
    st.stop()

st.success("‚úÖ System Ready!")

# ============================================================================
# TABS
# ============================================================================
tab1, tab2, tab3 = st.tabs(["üìä Manual Analysis", "üìÅ Batch CSV", "‚ÑπÔ∏è About"])

# ============================================================================
# TAB 1: MANUAL ANALYSIS
# ============================================================================
with tab1:
    st.markdown("## üìù Enter Network Traffic Features")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("Basic Parameters")
        duration = st.number_input("Duration (seconds)", 0, 100000, 45)
        src_bytes = st.number_input("Source Bytes", 0, 1000000, 1024)
        dst_bytes = st.number_input("Dest Bytes", 0, 1000000, 2048)
        land = st.number_input("Land (0/1)", 0, 1, 0)
    
    with col2:
        st.subheader("Connection Info")
        urgent = st.number_input("Urgent", 0, 100, 0)
        hot = st.number_input("Hot", 0, 100, 0)
        num_failed_logins = st.number_input("Failed Logins", 0, 100, 0)
        logged_in = st.number_input("Logged In (0/1)", 0, 1, 1)
    
    with col3:
        st.subheader("Error Rates (0.0-1.0)")
        serror_rate = st.number_input("SYN Error Rate", 0.0, 1.0, 0.0, step=0.0001, format="%.4f")
        srv_serror_rate = st.number_input("Srv SYN Error", 0.0, 1.0, 0.0, step=0.0001, format="%.4f")
        rerror_rate = st.number_input("Reset Error Rate", 0.0, 1.0, 0.0, step=0.0001, format="%.4f")
        same_srv_rate = st.number_input("Same Srv Rate", 0.0, 1.0, 1.0, step=0.0001, format="%.4f")
    
    st.markdown("---")
    
    protocol = st.radio("Protocol Type", ["TCP (6)", "UDP (17)", "ICMP (1)"], horizontal=True, index=0)
    service = st.radio("Service", ["HTTP (0)", "SMTP (1)", "FTP (6)", "SSH (5)"], horizontal=True, index=0)
    flag = st.radio("Flag", ["SF (0)", "S0 (1)", "REJ (2)", "SH (7)"], horizontal=True, index=0)
    
    protocol_num = int(protocol.split("(")[1].split(")")[0])
    service_num = int(service.split("(")[1].split(")")[0])
    flag_num = int(flag.split("(")[1].split(")")[0])
    
    if st.button("üîç ANALYZE TRAFFIC", use_container_width=True):
        try:
            # Build input dictionary with all 41 features
            input_dict = {
                'duration': float(duration),
                'protocol_type': float(protocol_num),
                'service': float(service_num),
                'flag': float(flag_num),
                'src_bytes': float(src_bytes),
                'dst_bytes': float(dst_bytes),
                'land': float(land),
                'wrong_fragment': 0.0,
                'urgent': float(urgent),
                'hot': float(hot),
                'num_failed_logins': float(num_failed_logins),
                'logged_in': float(logged_in),
                'num_compromised': 0.0,
                'root_shell': 0.0,
                'su_attempted': 0.0,
                'num_root': 0.0,
                'num_file_creations': 0.0,
                'num_shells': 0.0,
                'num_access_files': 0.0,
                'num_outbound_cmds': 0.0,
                'is_host_login': 0.0,
                'is_guest_login': 0.0,
                'count': 50.0,
                'srv_count': 50.0,
                'serror_rate': float(serror_rate),
                'srv_serror_rate': float(srv_serror_rate),
                'rerror_rate': float(rerror_rate),
                'srv_rerror_rate': 0.0,
                'same_srv_rate': float(same_srv_rate),
                'diff_srv_rate': 0.1,
                'srv_diff_host_rate': 0.05,
                'dst_host_count': 100.0,
                'dst_host_srv_count': 100.0,
                'dst_host_same_srv_rate': 0.9,
                'dst_host_diff_srv_rate': 0.1,
                'dst_host_same_src_port_rate': 0.5,
                'dst_host_srv_diff_host_rate': 0.05,
                'dst_host_serror_rate': 0.0,
                'dst_host_srv_serror_rate': 0.0,
                'dst_host_rerror_rate': 0.0,
                'dst_host_srv_rerror_rate': 0.0
            }
            
            # Feature order (EXACT NSL-KDD)
            feature_order = [
                'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',
                'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',
                'num_compromised', 'root_shell', 'su_attempted', 'num_root',
                'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',
                'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',
                'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',
                'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',
                'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',
                'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',
                'dst_host_rerror_rate', 'dst_host_srv_rerror_rate'
            ]
            
            # Create feature array
            X = np.array([[input_dict[f] for f in feature_order]])
            
            # Apply scaler if available
            if scaler is not None and not isinstance(scaler, (list, dict)):
                try:
                    X = scaler.transform(X)
                except:
                    pass
            
            # Make prediction
            prediction = model.predict(X)[0]
            
            # Get probabilities - SAFE WAY
            proba = model.predict_proba(X)[0]
            
            # Handle case where proba might have different shape
            if len(proba) == 2:
                normal_prob = proba[0] * 100
                attack_prob = proba[1] * 100
            else:
                # Single class prediction
                normal_prob = 50.0
                attack_prob = 50.0
            
            confidence = max(normal_prob, attack_prob)
            
            st.markdown("---")
            
            if prediction == 0:
                # NORMAL TRAFFIC
                st.markdown('<div class="result-normal">‚úÖ NORMAL TRAFFIC DETECTED</div>', unsafe_allow_html=True)
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Confidence", f"{confidence:.1f}%")
                with col2:
                    st.metric("Threat Level", "üü¢ LOW")
                with col3:
                    st.metric("Action", "‚úÖ ALLOW")
                st.success("‚úÖ This traffic is SAFE. Connection ALLOWED!")
            else:
                # ATTACK DETECTED
                st.markdown('<div class="result-attack">üö® ATTACK DETECTED!</div>', unsafe_allow_html=True)
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Confidence", f"{confidence:.1f}%")
                with col2:
                    st.metric("Threat Level", "üî¥ HIGH")
                with col3:
                    st.metric("Action", "‚ùå BLOCK")
                st.error("‚ö†Ô∏è INTRUSION DETECTED! IP address BLOCKED immediately!")
        
        except Exception as e:
            st.error(f"‚ùå Error: {str(e)}")

# ============================================================================
# TAB 2: BATCH CSV ANALYSIS
# ============================================================================
with tab2:
    st.markdown("## üìÅ Batch CSV Analysis")
    st.info("üìå Upload CSV with NSL-KDD format (41 features)")
    
    file = st.file_uploader("Upload CSV file", type=['csv'])
    
    if file:
        try:
            df = pd.read_csv(file)
            st.dataframe(df.head(10), use_container_width=True)
            
            if st.button("üîç ANALYZE BATCH", use_container_width=True):
                try:
                    # Use feature_names if available
                    if feature_names and len(feature_names) > 0:
                        cols = feature_names
                    else:
                        cols = df.columns.tolist()
                    
                    X = df[cols]
                    
                    # Scale if scaler available
                    if scaler is not None and not isinstance(scaler, (list, dict)):
                        try:
                            X = scaler.transform(X)
                        except:
                            pass
                    
                    # Predict
                    predictions = model.predict(X)
                    
                    # Add results
                    df['Prediction'] = ['üü¢ Normal' if p == 0 else 'üî¥ Attack' for p in predictions]
                    
                    normal_count = (predictions == 0).sum()
                    attack_count = (predictions == 1).sum()
                    
                    # Display metrics
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Normal Traffic", normal_count)
                    with col2:
                        st.metric("Attacks Detected", attack_count)
                    with col3:
                        rate = (attack_count / len(predictions) * 100) if len(predictions) > 0 else 0
                        st.metric("Detection Rate", f"{rate:.1f}%")
                    
                    st.markdown("---")
                    st.dataframe(df, use_container_width=True)
                    
                    # Download button
                    csv_data = df.to_csv(index=False)
                    st.download_button("üì• Download Results", csv_data, "idps_results.csv", "text/csv")
                
                except Exception as e:
                    st.error(f"‚ùå Analysis Error: {str(e)}")
        except Exception as e:
            st.error(f"‚ùå File Error: {str(e)}")

# ============================================================================
# TAB 3: ABOUT
# ============================================================================
with tab3:
    st.markdown("""
    ## üéØ IDPS System - Real-World Edition
    
    ### üìä Dataset: NSL-KDD
    - **Samples:** 125,973 training records
    - **Features:** 41 network parameters
    - **Labels:** Normal (0) vs Attack (1)
    
    ### ü§ñ Model: Random Forest
    - **Accuracy:** >99%
    - **Trees:** 200
    
    ### üéØ Attack Types Detected
    - DoS, Probe, R2L, U2R
    
    ### üìå Test Values
    **Normal Traffic:** All error rates = 0.0, Protocol = TCP, Service = HTTP/SMTP/FTP/SSH
    **Attack Traffic:** High error rates, suspicious flags, unusual byte counts
    
    ---
    *IDPS v5.0 | Production Ready | December 2025*
    """)
